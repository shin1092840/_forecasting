import re
from functools import partial
from glob import glob

import lightgbm as lgb
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import missingno as msno
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import KFold
from xfeat import (ArithmeticCombinations, ConcatCombination,
                   GBDTFeatureExplorer, GBDTFeatureSelector, LabelEncoder,
                   LambdaEncoder, Pipeline, SelectCategorical, SelectNumerical,
                   TargetEncoder, aggregation)

sns.set()

#次にしたいアプローチ
#IsolationForestまたは（決定木をベース）
#EllipticEnvelope（ベイズをベース）
#を用いてOutliresを検出して、それらを通常な値で予測したモデルの値で置き換える

# データ前処理用関数を作成

def normalize_moyori(moyori):
    if moyori == moyori:
        if moyori == '30分?60分':
            moyori = 45
        elif moyori == '1H?1H30':
            moyori = 75
        elif moyori == '1H30?2H':
            moyori = 105
        elif moyori == '2H?':
            moyori = 120
        moyori = int(moyori)
    return moyori


def normalize_area(area):
    if area == area:
        area = int(re.sub('m\^2未満|㎡以上', '', str(area)))
    return area


def convert_wareki_to_seireki(wareki):
    if wareki == wareki:
        if wareki == '戦前':
            wareki = '昭和20年'
        value = wareki[2:-1]
        if value == '元':
            value = 1
        else:
            value = int(value)
        if '昭和' in wareki:
            seireki = 1925+value
        elif '平成' in wareki:
            seireki = 1988+value
        elif '令和' in wareki:
            seireki = 2018+value
    else:
        seireki = wareki
    return seireki

def outlier_2s(df):

    # 列を抽出する
    col = df["取引価格（総額）_log"]

    # 平均と標準偏差
    average = np.mean(col)
    sd = np.std(col)

    # 外れ値の基準点
    outlier_min = average - (sd) * 2.5
    outlier_max = average + (sd) * 2.5

    # 範囲から外れている値を除く
    col[col < outlier_min] = None
    col[col > outlier_max] = None

    return df

def convert_room_to_numbers(room):
    if room == room:
        if "オープンフロア" or "スタジオ" or "メゾネット" or "nan" in room:
            room = 1
        elif "＋" in room:
            if "１" in room:
                room = len(room)-1
            elif "２" in room:
                room = len(room)
            elif "３" in room:
                room = len(room)+1
            elif "４" in room:
                room = len(room)+2
            elif "５" in room:
                room = len(room)+3
            elif "６" in room:
                room = len(room)+4
            elif "７" in room:
                room = len(room)+5
            elif "８" in room:
                room = len(room)+6
        else:
            if "１" in room:
                room = len(room)
            elif "２" in room:
                room = len(room)+1
            elif "３" in room:
                room = len(room)+2
            elif "４" in room:
                room = len(room)+3
            elif "５" in room:
                room = len(room)+4
            elif "６" in room:
                room = len(room)+5
            elif "７" in room:
                room = len(room)+6
            elif "８" in room:
                room = len(room)+7
    return room

# データ読み込み

paths = glob('train/*.csv')
train_dfs = []
for path in paths:
    train_df = pd.read_csv(path)
    train_dfs.append(train_df)
train_df = pd.concat(train_dfs)
train_df.reset_index(drop=True, inplace=True)
test_df = pd.read_csv('test.csv')

sub_df = pd.read_csv('sample_submission.csv')


ID = 'ID'
TARGET = '取引価格（総額）_log'
rm_cols = []

test_df[TARGET] = np.nan
df = pd.concat([train_df, test_df])

rm_cols += ['市区町村コード']

for i, v in df.nunique().iteritems():
    if v <= 1:
        rm_cols.append(i)

train_df.drop(rm_cols, axis=1, inplace=True)
test_df.drop(rm_cols, axis=1, inplace=True)
df = pd.concat([train_df, test_df])

#EDA
sns.displot(train_df["取引価格（総額）_log"])
plt.show()
msno.bar(train_df)
plt.show()

train_df["取引価格（総額）_log"]*1000000
train_df["取引価格（総額）_log"] = train_df["取引価格（総額）_log"].astype(int)
print(train_df["取引価格（総額）_log"].isnull().any())
train_df.dropna(subset=["取引価格（総額）_log"],inplace=True)
print(train_df.info())

# 特徴量生成

enc_dic = {}
for i, e in enumerate(sorted(list(set(df['取引時点'].values)))):
    enc_dic[e] = i
df['取引時点_enc'] = df['取引時点'].map(enc_dic)

# Target Encoding
# ある行の特徴量として平均値を計算するのに、その時点で過去に登場したデータの集計を用いる
# 以下例では、都道府県ごとに各取引時点より過去の値の平均値を用いる
te_dic = {}
time_col = '取引時点_enc'
group_col = '都道府県名'

for i in set(df[time_col].values):
    tmp_df = df[df[time_col] < i]
    te_dic[i] = tmp_df.groupby(group_col)[TARGET].agg('mean').to_dict()


def calc_te(row):
    if row[time_col] in te_dic and row[group_col] in te_dic[row[time_col]]:
        return te_dic[row[time_col]][row[group_col]]
    else:
        return 0


df[group_col+'_te'] = df.apply(calc_te, axis=1)

df['取引時点_何年前'] = df['取引時点'].apply(lambda x: 2020-int(x[:4]))
df.drop(['取引時点'], axis=1, inplace=True)
df['建築年'] = df['建築年'].apply(lambda x: convert_wareki_to_seireki(x))
df['面積（㎡）'] = df['面積（㎡）'].apply(lambda x: normalize_area(x))
df['最寄駅：距離（分）'] = df['最寄駅：距離（分）'].apply(lambda x: normalize_moyori(x))

print(df["間取り"].unique())

#部屋数コラム
#1部屋当たりの面積
df["numberofrooms"] = df["間取り"].apply(lambda x: convert_room_to_numbers(x))
df["surfaceareaperroom"] = df["面積（㎡）"]/df["numberofrooms"]

print(df.info())
#郵便番号と市ごとの物件数
#緯度経度を四則演算

# 数値データを抽出しておく
num_df = SelectNumerical().fit_transform(df)

# カテゴリカルデータを抽出
encoder = Pipeline([
    SelectCategorical(),
    LabelEncoder(output_suffix=""),
])

le_df = encoder.fit_transform(df)

# 数値データを組み合わせた特徴量生成
encoder = Pipeline(
    [
        SelectNumerical(),
        ArithmeticCombinations(
            input_cols=["面積（㎡）", "容積率（％）","surfaceareaperroom","numberofrooms"],
            drop_origin=True,
            operator="*",
            r=2,
        ),
    ]
)

num_comb_df = encoder.fit_transform(df)/100

# 集約特徴量生成
agg_dfs = []


def get_agg_df(df, group_col):

    agg_df, agg_cols = aggregation(df,
                                   group_key=group_col,
                                   # '前面道路：幅員（ｍ）',
                                   group_values=['最寄駅：距離（分）',
                                                 '面積（㎡）', '建ぺい率（％）', '容積率（％）',"surfaceareaperroom","numberofrooms"],
                                   agg_methods=['count', 'mean', 'min', 'max'],
                                   )

    return agg_df[agg_cols]


group_col = '市区町村名'
agg_dfs.append(get_agg_df(df, group_col))

# 生成した特徴量を結合
feat_df = pd.concat([num_df, le_df, num_comb_df]+agg_dfs, axis=1)

print(df.info())
# モデル構築
train_df = feat_df[feat_df['取引時点_何年前'] > 1]
val_df = feat_df[feat_df['取引時点_何年前'] == 1]
test_df = feat_df[feat_df['取引時点_何年前'] == 0]

feat_cols = [col for col in train_df.columns if col not in rm_cols+[ID, TARGET]]

cat_cols = list(le_df.columns) + ['取引時点_enc']

train_x = train_df[feat_cols]
train_y = train_df[TARGET]
val_x = val_df[feat_cols]
val_y = val_df[TARGET]
test_x = test_df[feat_cols]
test_y = test_df[TARGET]

SEED = 0

params = {
    'objective': 'regression',
    'metric': 'mae',
    'num_leaves': 42,
    'max_depth': 8,
    "feature_fraction": 0.8,
    'subsample_freq': 1,
    "bagging_fraction": 0.95,
    'min_data_in_leaf': 2,
    'learning_rate': 0.1,
    "boosting": "gbdt",
    "lambda_l1": 0.1,
    "lambda_l2": 10,
    "verbosity": -1,
    "random_state": 42,
    "num_boost_round": 50000,
    "early_stopping_rounds": 100
}

train_data = lgb.Dataset(train_x, label=train_y)
val_data = lgb.Dataset(val_x, label=val_y)

model = lgb.train(
    params,
    train_data,
    categorical_feature=cat_cols,
    valid_names=['train', 'valid'],
    valid_sets=[train_data, val_data],
    verbose_eval=100,
)

val_pred = model.predict(val_x, num_iteration=model.best_iteration)
score = mean_absolute_error(val_y, val_pred)

pred_df = pd.DataFrame(sorted(zip(val_x.index, val_pred, val_y)), columns=[
                       'index', 'predict', 'actual'])

feature_imp = pd.DataFrame(sorted(zip(model.feature_importance(
), train_x.columns)), columns=['importance', 'feature'])

print(f'score: {score:.4f}')
# score: 0.0918

# 特徴量の重要度可視化
lgb.plot_importance(model, figsize=(
    12, 8), max_num_features=50, importance_type='gain')
plt.tight_layout()
plt.show()

test_pred = model.predict(test_x, num_iteration=model.best_iteration)

# 投稿ファイル作成
sub_df[TARGET] = test_pred
sub_df.to_csv('test_submission.csv', index=False)
